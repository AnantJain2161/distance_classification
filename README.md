# distance_classification
![image](https://github.com/user-attachments/assets/37c05b15-9136-49dd-b7b9-4b022545852e)

Report:
1. Common distance metrics: Euclidean, Manhattan, Minkowski, Cosine, Hamming.
2. Real-world applications: Face recognition, image retrieval, fraud detection, medical diagnosis, document classification.
3. Distance metrics explained:
   - Euclidean: Straight-line distance.
   - Manhattan: Sum of absolute differences.
   - Minkowski: Generalization of Euclidean and Manhattan.
   - Cosine Similarity: Measures cosine of the angle between vectors.
   - Hamming: Number of differing bits.
4. Cross-validation: Helps in assessing model performance by reducing bias/variance.
5. Variance and bias in KNN:
   - Low k: Low bias, high variance.
   - High k: Higher bias, lower variance.


   ![image](https://github.com/user-attachments/assets/92b654fb-7785-4c35-9438-edd2eb415306)

   
   ![image](https://github.com/user-attachments/assets/07084c3c-236e-4597-a828-bd4e5c35e743)

   
   ![image](https://github.com/user-attachments/assets/00a82972-49df-47aa-a10b-0da90a3b5d24)

   
   ![image](https://github.com/user-attachments/assets/2116dbc5-469b-449d-a058-36513784b5a6)
   

   ![image](https://github.com/user-attachments/assets/a6382a27-609c-4aeb-836b-d87d4e80560d)
